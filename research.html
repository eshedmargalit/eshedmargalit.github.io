<!doctype html>
<html class="no-js" lang="en">

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Eshed Margalit | Research</title>
    <link rel="stylesheet" href="css/foundation.min.css">
    <link rel="stylesheet" href="css/app.css">
    <link rel="icon" data-emoji="üß†" type="image/png">
    <link href='https://fonts.googleapis.com/css?family=Anonymous+Pro:400,700' rel='stylesheet' type='text/css'>
</head>

<body>

    <div class="top-bar">
        <div class="top-bar-left">
            <ul class="menu">
                <a href="index.html">
                    <li class="menu-text">Home</li>
                </a>
            </ul>
        </div>
        <div class="top-bar-right">
            <ul class="menu">
                <li><a href="research.html">Research</a></li>
                <li><a href="CV.html">CV</a></li>
                <li><a href="contact.html">Contact</a></li>
            </ul>
        </div>
    </div>

    <div class="callout large">
        <div class="row">
            <div class="medium-4 columns end">
                <h1>My Research</h1>

                <p>Read on to see some of the things I'm interested in, or click the button below to check out my
                    Google Scholar profile.</p>
                <a href="https://scholar.google.com/citations?user=ijttsicAAAAJ&hl=en&oi=ao" class="button large">Google
                    Scholar Profile</a>
            </div>
        </div>
    </div>

    <!--PROJECTS ROW-->
    <div class="row">
        <div class="medium-12 columns">

            <!--SpaceNet-->
            <div class="row">
                <div class="medium-9 columns">
                    <h3>Modeling the Development of the Visual Brain</h3>
                    <p>
                        The visual system is full of rich and interesting phenomena,
                        many of which are poorly understood. We are using deep
                        convolutional neural networks to model the development of the
                        ventral visual system, which is thought to be responsible for
                        recognizing objects. Large-scale models of the development
                        of this system will enable us to understand how
                        an animal's experience may affect the structure and
                        development of its visual system.
                    </p>
                    <p>
                        <a href="img/Margalit_et_al_VSS_2018.png" class="button">
                            See poster here!
                        </a>
                    </p>
                </div>
                <div class="medium-3 columns">
                    <img class="circlePhoto" src="img/spacenet.png" alt="Orientation preference map from a model of the visual system" />
                </div>
            </div>
            <hr>

            <!--Functional Architecture-->
            <div class="row">
                <div class="medium-3 columns">
                    <img class="circlePhoto" src="img/charvall_map.png" alt="fMRI statistical activation map" />
                </div>
                <div class="medium-9 columns">
                    <h3>Characterizing the Fine Scale Functional Architecture of the Ventral Temporal Cortex</h3>
                    <p>
                        Recent advances in fMRI technology have allowed insights
                        into the functional organization of cortical regions at
                        unprecented resolution. In collaboration with the
                        <a href="http://cvnlab.net"> CVN Lab at the University
                            of Minnesota </a>, we are examining areas of the
                        brain that preferentially respond to different object
                        categories and studying their arrangement in the brain.
                    </p>
                </div>

            </div>
            <hr />

            <!--Gabor-jet Model-->
            <div class="row">
                <div class="medium-9 columns">
                    <h3>Interactive Web Application for Gabor-jet Model</h3>
                    <p>
                        The Gabor-jet model is a tool used to compute the
                        psychophysical dissimilarity between images:
                        an objective metric of how dissimilar two images
                        appear. The model predicts over 90% of the variance
                        in human responses on a match-to-sample task with
                        artificial face stimuli, making it an invaluable tool
                        in psychophysical research. I designed
                        <a href="http://geon.usc.edu/~GJW">this webpage</a> to
                        act as an interactive guided tour of the model,
                        allowing users to upload and test their own stimuli
                        in-browser. Follow the link above to learn more about
                        the model or to try it yourself!</p>
                    <hr class="short">
                    <h5>References</h5>
                    <ul>
                        <li>
                            <a href="http://geon.usc.edu/~biederman/publications/Margalit_et_al_2016_Gabor_Applet_APP.pdf">
                                Margalit, E., Herald, S.B., Yue, X., von der Malsburg, C.,
                                & Biederman, I. An applet for the Gabor Scaling of the Differences
                                Between Complex Stimuli. <em>Attention, Perception, and Psychophysics,
                                    78(8), 2298-2306.</em></a></li>
                    </ul>
                </div>
                <div class="medium-3 columns">
                    <img class="circlePhoto" src="img/gabor_grab.PNG" alt="Sample screenshot from Gabor-jet web site" />
                </div>
            </div>
            <hr>

            <!--Object Familiarity in LOC-->
            <div class="row">
                <div class="medium-3 columns">
                    <img class="circlePhoto" src="img/LOC_mricrogl.png" alt="Figure from Margalit et al." />
                </div>
                <div class="medium-9 columns">
                    <h3>Object Familiarity in LOC</h3>
                    <p>Hundreds of studies have explored the Lateral Occipital Complex
                        (LOC), which is critical for shape perception. Early studies
                        discounted a role of familiarity by showing that ‚Äúabstract‚Äù sculptures,
                        unfamiliar to the subjects, also activated this region.
                        This characterization of LOC as a region that responds to
                        shape independently of familiarity had been accepted but
                        never tested with control of the same low-level features.
                        We assessed LOC‚Äôs response to objects that had identical
                        parts in two different arrangements, one familiar and
                        the other novel. Malach was correct: there is no net
                        effect of familiarity in LOC. However, a MVPA showed
                        that LOC does distinguish familiar from novel objects.</p>
                    <p><em>Abstract adapted from <a href="http://jov.arvojournals.org/article.aspx?articleid=2551659">
                                Margalit et al., 2016</a></em></p>
                    <hr class="short">
                    <h5>References</h5>
                    <ul>
                        <li><a href="http://jov.arvojournals.org/article.aspx?articleid=2551659">
                                Margalit, E., Shah, M.P., Tjan, B.S., Biederman, I.,
                                Keller, B., & Brenner, R. The lateral occipital complex
                                shows no net response to object familiarity.
                                <em>Journal of Vision. 16(11), 3-3.</em></a></li>
                        <li>Biederman, I., Margalit, E., Tjan B.S., & Shah, M.P. (2016). What is actually affected by
                            the scrambling of objects when localizing LOC? Presented at the Annual Meeting of the
                            Vision Sciences Society, St. Petersburg Beach, FL. May.</li>
                    </ul>
                </div>

            </div>
            <hr>

            <!--Developmental Prosopagnosia-->
            <div class="row">
                <div class="medium-9 columns">
                    <h3>Developmental Prosopagnosia</h3>
                    <p>
                        Developmental prosopagnosics (DPs) present no lesions nor have a history of compromised neural
                        functioning. Given that their activation of face-selective cortex is normal, it surprised us
                        that their capacity to perceptually discriminate faces and non-face objects had never been
                        rigorously assessed. Normal discrimination of faces would suggest that the underlying deficit
                        might not be a consequence of a poor perceptual representation but, instead, difficulty in
                        matching a well-defined representation to stored representations in memory. If a deficit in
                        discriminating faces is observed, is it also manifested when discriminating non-face stimuli
                        that differ along the same underlying physical attributes as faces and to an equivalent extent
                        as the faces? We found that, indeed, DPs present deficits in discriminating both faces and
                        tooth-like blobs, but that this deficit does not extend to simple geometric primitives.
                    </p>
                    <p><a href="http://geon.usc.edu/~biederman/presentations/Margalit_et_al_VSS_16.pdf" class="button">See
                            poster here!</a></p>
                    <hr class="short">
                    <h5>References</h5>
                    <ul>
                        <li>Margalit, E., Juarez, J., Herald, S.B., Yue, X., & Biederman, I. (2016). What might be the
                            General Visual Deficit that Underlies Developmental Prosopagnosia? Presented at the Annual
                            Meeting of the Vision Sciences Society, St. Petersburg Beach, FL. May.</li>
                    </ul>
                </div>
                <div class="medium-3 columns">
                    <img src="img/Hist2.png" alt="Sample figure from poster" />
                </div>

            </div>

        </div>
    </div>
    <hr>

    <div class="row">
        <div class="medium-4 columns medium-offset-8">
            <ul class="menu">
                <li><a href="research.html">Research</a></li>
                <li><a href="CV.html">CV</a></li>
                <li><a href="contact.html">Contact</a></li>
            </ul>
        </div>
    </div>
    <hr>
    <div class="row medium-6 medium-offset-3 columns end">
        <p>Website designed by Eshed Margalit using <a href="http://foundation.zurb.com/">ZURB Foundation</a>.</p>
    </div>

    <script src="js/vendor/jquery.js"></script>
    <script src="js/vendor/foundation.js"></script>
    <script>
        $(document).foundation();

        // dynamically set favicon
        const favicon = document.querySelector("link[rel=icon]");
        if (favicon) {
            const emoji = favicon.getAttribute("data-emoji");

            if (emoji) {
                const canvas = document.createElement("canvas");
                canvas.height = 64;
                canvas.width = 64;

                const ctx = canvas.getContext("2d");
                ctx.font = "64px serif";
                ctx.fillText(emoji, 0, 64);

                favicon.href = canvas.toDataURL();
            }
        }
    </script>
</body>

</html>